{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data feature\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# get horitonzal edges from sobelY\n",
    "def number_of_edgePixels(image):\n",
    "    sobelY = cv2.Sobel(image, cv2.CV_64F,0,1,ksize=5)\n",
    "    return np.count_nonzero(sobelY==255)\n",
    "\n",
    "# std of mean of rows, get high value for black/white horisontal stripes.\n",
    "def std_meanOfRows(image):\n",
    "    mean_row = np.mean(image, axis=1)\n",
    "    return np.std(mean_row, dtype=np.float32)\n",
    "\n",
    "# mean number of peak and valleys in each column, get high value for noisy pictures.\n",
    "def mean_PeaksValleys(image):\n",
    "    peaks_valleys = []\n",
    "    for j in range(image.shape[1]):\n",
    "        col = image[:, j]\n",
    "        num_peaks, num_valleys = count_peaks_valleys(col)\n",
    "        mean_peaks_valleys = (num_peaks + num_valleys) / 2\n",
    "        peaks_valleys.append(mean_peaks_valleys)\n",
    "    return np.mean(peaks_valleys, dtype=np.float32)\n",
    "    \n",
    "def count_peaks_valleys(arr_1d):\n",
    "    num_peaks = 0\n",
    "    num_valleys = 0\n",
    "    for i in range(1, len(arr_1d) - 1):\n",
    "        if arr_1d[i] > arr_1d[i-1] and arr_1d[i] > arr_1d[i+1]:\n",
    "            num_peaks += 1\n",
    "        elif arr_1d[i] < arr_1d[i-1] and arr_1d[i] < arr_1d[i+1]:\n",
    "            num_valleys += 1\n",
    "    return (num_peaks, num_valleys)\n",
    "\n",
    "# numbers of edges from canny edge detection, use dfs to explore number of group of edge pixels\n",
    "def num_edges_canny(image, L2Gradient, sobel_kernal_size):\n",
    "    T_lower = 100\n",
    "    T_upper = 200 \n",
    "    edge = cv2.Canny(image, T_lower, T_upper, apertureSize=sobel_kernal_size, L2Gradient = L2Gradient)\n",
    "    def dfs(r, c):\n",
    "        if r < 0 or r >= np.size(image, 0) or c < 0 or c >= np.size(image, 1) or image[r][c] == 0:\n",
    "            return 0\n",
    "            \n",
    "        image[r][c] = 0\n",
    "            \n",
    "        for i, j in zip((r - 1, r + 1, r, r), (c, c, c - 1, c + 1)):\n",
    "            dfs(i, j)\n",
    "            \n",
    "        return 1\n",
    "    \n",
    "    return sum(dfs(i, j) for i in range(np.size(image, 0)) for j in range(np.size(image, 1)))\n",
    "\n",
    "def lbp_histogram(image, radius, bins):\n",
    "    # compute the LBP histogram of the image\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp, bins= bins, density=True)\n",
    "    return np.ravel(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2910, 4)\n"
     ]
    }
   ],
   "source": [
    "# example of using features to train model\n",
    "# number_image = 2910\n",
    "# feature = 4\n",
    "# img=np.zeros(shape=(number_image,feature))\n",
    "# for i in range(0,number_image): \n",
    "#     img[i][0] = number_of_edgePixels(npdata['data'][i])\n",
    "#     img[i][1] = std_meanOfRows(npdata['data'][i])\n",
    "#     img[i][2] = mean_PeaksValleys(npdata['data'][i])\n",
    "#     img[i][3] = np.std(npdata['data'][i])\n",
    "# print(img.shape)\n",
    "# dataset = Bunch(data = img, target=npdata['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Training Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       686\n",
      "           1       0.93      0.88      0.90       625\n",
      "           2       0.93      0.96      0.94      1017\n",
      "\n",
      "    accuracy                           0.95      2328\n",
      "   macro avg       0.95      0.95      0.95      2328\n",
      "weighted avg       0.95      0.95      0.95      2328\n",
      "\n",
      "Train Confusion Matrix: \n",
      " [[686   0   0]\n",
      " [  2 548  75]\n",
      " [  0  42 975]] \n",
      "\n",
      "Train Accuracy:  0.9488831615120275\n",
      "\n",
      "\n",
      "Classification Testing Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       184\n",
      "           1       0.95      0.89      0.92       158\n",
      "           2       0.94      0.97      0.95       240\n",
      "\n",
      "    accuracy                           0.96       582\n",
      "   macro avg       0.96      0.95      0.96       582\n",
      "weighted avg       0.96      0.96      0.96       582\n",
      "\n",
      "Test Confusion Matrix: \n",
      " [[184   0   0]\n",
      " [  1 141  16]\n",
      " [  0   8 232]] \n",
      "\n",
      "Test Accuracy:  0.9570446735395189\n"
     ]
    }
   ],
   "source": [
    "# svm_model(dataset, 0.2, 'poly', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
