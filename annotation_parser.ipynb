{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unzip the exported dataset from CVAT  \n",
    "set zipfile name as CVAT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Setting\n",
    "\n",
    "zipfile_name = 'Img8_13_15'\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "with zipfile.ZipFile(f'{zipfile_name}.zip', 'r') as zf:\n",
    "    if not os.path.exists(f'{zipfile_name}'):\n",
    "        os.makedirs(f'{zipfile_name}')\n",
    "\n",
    "    zf.extractall(f'{zipfile_name}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Box Extraction\n",
    "`def image_names_parser(path)` -> return all image names from the annotations\n",
    "`def labels_parser(path, image_name)` -> return label boxs of corresponding image\n",
    "\n",
    "test: check if the box is in the right place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_names_parser(path):\n",
    "    tree = ET.parse(f'{path}/annotations.xml')\n",
    "    root = tree.getroot()\n",
    "    image_names = []\n",
    "    for image in root.findall('image'):\n",
    "        image_names.append(image.get('name'))\n",
    "    return image_names\n",
    "\n",
    "def labels_parser(path, image_name):\n",
    "    tree = ET.parse(f'{path}/annotations.xml')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    labels = {}\n",
    "    for i, label in enumerate(root.iter('label')):\n",
    "        labels[label.find('name').text] = i\n",
    "\n",
    "    image_node = None\n",
    "    for image in root.findall('image'):\n",
    "        if image.get('name') == image_name:\n",
    "            image_node = image\n",
    "\n",
    "    boxs = []\n",
    "    coordinates = ['xtl', 'ytl', 'xbr', 'ybr']\n",
    "    for i in range(len(labels)):\n",
    "        boxs.append([])\n",
    "    for box in image_node.findall('box'):\n",
    "        points = []\n",
    "        for coordinate in coordinates:\n",
    "            points.append(int(box.get(coordinate).split(\".\")[0]))\n",
    "        boxs[labels[box.get('label')]].append(points)\n",
    "\n",
    "    return boxs\n",
    "boxs = labels_parser(zipfile_name, 'WLT_350_210926 P_2111131 WLT_350_210926__008 P_2111131_processed.JPG')\n",
    "for i in range(len(boxs)):\n",
    "    print(boxs[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the annotations is shown as they are on CVAT\n",
    "set the index of images and the feature type in the CVAT annotations\n",
    "\n",
    "Flag of the feature type\n",
    "- strong hyperbola: 0\n",
    "- weak hyperbola: 1\n",
    "- strong reflector: 2\n",
    "- weak reflector: 3\n",
    "- other: 4\n",
    "- no feature: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Setting\n",
    "\n",
    "index = 0\n",
    "flag = 2\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "test_image = image_names_parser(zipfile_name)[index]\n",
    "boxs = labels_parser(zipfile_name, test_image)\n",
    "\n",
    "print(test_image)\n",
    "img = cv2.imread(f'processed/{test_image}')\n",
    "box_width = 3\n",
    "for box in boxs[flag]:\n",
    "    for i in range(3):\n",
    "        img[box[1] - box_width:box[1] + box_width, box[0]:box[2], i] = 90 * i * np.ones_like(img[box[1] - box_width:box[1] + box_width, box[0]:box[2], i])\n",
    "        img[box[3] - box_width:box[3] + box_width, box[0]:box[2], i] = 90 * i * np.ones_like(img[box[3] - box_width:box[3] + box_width, box[0]:box[2], i])\n",
    "        img[box[1]:box[3], box[0] - box_width:box[0] + box_width, i] = 90 * i * np.ones_like(img[box[1]:box[3], box[0] - box_width:box[0] + box_width, i])\n",
    "        img[box[1]:box[3], box[2] - box_width:box[2] + box_width, i] = 90 * i * np.ones_like(img[box[1]:box[3], box[2] - box_width:box[2] + box_width, i])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_out_of_box(sliding_window, box):\n",
    "    if sliding_window[2] < box[0] or sliding_window[0] > box[2]:\n",
    "        return True\n",
    "    if sliding_window[3] < box[1] or sliding_window[1] > box[3]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_box(sliding_window, box, overlapping):\n",
    "    if check_out_of_box(sliding_window, box):\n",
    "        return False\n",
    "    \n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    sliding_window_area = (sliding_window[2] - sliding_window[0]) * (sliding_window[3] - sliding_window[1])\n",
    "    overlap_area = (min(sliding_window[2], box[2]) - max(sliding_window[0], box[0])) * (min(sliding_window[3], box[3]) - max(sliding_window[1], box[1]))\n",
    "    if overlap_area / min(box_area, sliding_window_area) < overlapping:\n",
    "        return False    \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(save_path, image_name, boxs, flag, overlapping, sliding_window_size=200, step=100):\n",
    "    img = cv2.imread(f'{save_path}/{image_name}')\n",
    "    feature_type = ['strong hyperbola', 'weak hyperbola', 'strong reflector', 'weak reflector', 'other', 'no feature']\n",
    "    # exclude the left axis and data above 0 ms\n",
    "    # Boundary constant of images\n",
    "    IMAGE_START = 64\n",
    "    AXIS_ZERO = 121\n",
    "    img = img[AXIS_ZERO:, IMAGE_START:]\n",
    "\n",
    "    if not os.path.exists(f'{save_path}/cropped/{sliding_window_size}_{step}/{flag}'):\n",
    "        os.makedirs(f'{save_path}/cropped/{sliding_window_size}_{step}/{flag}')\n",
    "\n",
    "    for j in range(0, img.shape[0] - 1, step):\n",
    "        count = 0\n",
    "        for path in os.listdir(f'{save_path}/cropped/{sliding_window_size}_{step}/{flag}'):\n",
    "            if path.startswith(f'{j}_'):\n",
    "                count += 1\n",
    "\n",
    "        for i in range(0, img.shape[1] - 1, step):\n",
    "            if j + sliding_window_size > img.shape[0] - 1 or i + sliding_window_size > img.shape[1] - 1:\n",
    "                continue\n",
    "\n",
    "            sliding_window = [i, j, i + sliding_window_size, j + sliding_window_size]\n",
    "            if flag < 5:\n",
    "                for box in boxs[flag]:\n",
    "                    # Check if the box is overlapping over 80%, if not don't label it            \n",
    "                    if check_box(sliding_window, box, overlapping):\n",
    "                        sub_img = img[j:j + sliding_window_size, i:i + sliding_window_size]\n",
    "                        cv2.imwrite(f'{save_path}/cropped/{sliding_window_size}_{step}/{flag}/{j}_{count}.jpg', sub_img)\n",
    "                        count += 1\n",
    "                        break\n",
    "            else:\n",
    "                all_boxs = [box for label_type in boxs for box in label_type]\n",
    "                is_out_of_box = True\n",
    "                for box in all_boxs:\n",
    "                    if not check_out_of_box(sliding_window, box):\n",
    "                        is_out_of_box = False\n",
    "                        break\n",
    "                if is_out_of_box:\n",
    "                    sub_img = img[j:j + sliding_window_size, i:i + sliding_window_size]\n",
    "                    cv2.imwrite(f'{save_path}/cropped/{sliding_window_size}_{step}/{flag}/{j}_{count}.jpg', sub_img)\n",
    "                    count += 1\n",
    "\n",
    "    print(f'Finished generating images of {feature_type[flag]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the save path of cropped images\n",
    "The cropped image save in the processed directory in default.\n",
    "\n",
    "### Parameter\n",
    "- save_path: default in 'processed'\n",
    "- flag: feature type. If all kind of feature is required, run through flag 0-5\n",
    "- sliding_window_size: size of the cropped images. 200 x 200 pixels in default\n",
    "- step: step of sliding window. 100 pixels in default\n",
    "- overlapping: acceptance rate of overlapping of sliding windows and feature box. 0.8 in default, which means that sliding window covers above 80% of feature box\n",
    "\n",
    "Flag of the feature type\n",
    "- strong hyperbola: 0\n",
    "- weak hyperbola: 1\n",
    "- strong reflector: 2\n",
    "- weak reflector: 3\n",
    "- other: 4\n",
    "- no feature: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Setting\n",
    "\n",
    "save_path = 'processed'\n",
    "flag = 0\n",
    "sliding_window_size = 200\n",
    "step = 40\n",
    "overlapping = 0.8\n",
    "\n",
    "# ==================================================\n",
    "\n",
    "image_names = image_names_parser(zipfile_name)\n",
    "for image_name in image_names:\n",
    "    boxs = labels_parser(zipfile_name, image_name)\n",
    "    count = crop_image(save_path, image_name, boxs, flag, overlapping, sliding_window_size=sliding_window_size, step=step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
